# -*- coding: utf-8 -*-
"""Major Project(Sentiment Analysis).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jma-7x7jXYIMNZts2YdU4D0TEdZn_6-U
"""

import pandas as pd
import numpy as np
from scipy.stats import randint
from io import StringIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import chi2
from IPython.display import display
from sklearn.model_selection import train_test_split
import seaborn as sns # used for plot interactive graph. 
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn import metrics
import nltk
nltk.download('stopwords')

# Data loading from csv
df = pd.read_csv('/content/drive/MyDrive/Major Project(Smartknower)/Dataset.csv')
df.shape

df.head()

import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sid = SentimentIntensityAnalyzer()
df['score2'] = df['Tweet'].apply(lambda review: sid.polarity_scores(review))

df.head()

df['compound']  = df['score2'].apply(lambda score_dict: score_dict['compound'])

df.head()

df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')

df.head()

df = df.sort_values(by ='compound' )
print("Contents of Sorted Dataframe based on a single column 'compound' : ")
df

df.describe()

df.groupby('comp_score').describe()

df['length'] = df['Tweet'].apply(len)
df.head()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

df['length'].plot(bins=100, kind='hist')

df.length.describe()

df.hist(column='length', by='comp_score', bins=50,figsize=(20,6))

#Testing compound score for a brand new text

from nltk.sentiment.vader import SentimentIntensityAnalyzer
sid = SentimentIntensityAnalyzer()
text_msg=input("Enter your text to analyze the sentiment")
print(text_msg)
# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text
scores = sid.polarity_scores(text_msg)

# Here we loop through the keys contained in scores (pos, neu, neg, and compound scores) and print the key-value pairs on the screen

for key in sorted(scores):
        print('{0}: {1}, '.format(key, scores[key]), end='')

!pip install streamlit --quiet
!pip install pyngrok==4.1.1 --quiet
from pyngrok import ngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import numpy as np
# st.title('Sentiment Analysis')
# st.text_input("Enter the Text for which you want to analyze the sentiment")
# st.write(st.text_input)
# st.write('Result...')
# from nltk.sentiment.vader import SentimentIntensityAnalyzer
# sid = SentimentIntensityAnalyzer()
# scores = sid.polarity_scores(st.text_input)
# for key in sorted(scores):
#   st.write('{0}: {1}, '.format(key, scores[key]), end='')
# else:
#   st.write("Please enter some text")

!nohup streamlit run app.py &
url=ngrok.connect(port='8501')
url